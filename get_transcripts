import glob
import json
import os.path
import time

import requests
from bs4 import BeautifulSoup

path_to_root = "/Users/pang/repos/scotus"


def check_file(file):
    """
    Checks if given file exists.
    :param file: File to check
    :return: True if file found, False if file not found
    """
    if os.path.isfile(file):
        print(f"Found {file}. Skipping")
        return True
    else:
        False


def get_transcript_html(year):
    """
    Goes to Supreme Court site for given year and pulls the full HTML from that site
    Does not grab HTML if file already exists in output path
    :param year: Gets transcripts for the year
    :return: None
    """

    file_to_write = f"{path_to_root}/data/001_html/001_html_{year}.txt"
    if check_file(file_to_write):
        return None

    url = f"https://www.supremecourt.gov/oral_arguments/argument_transcript/{year}"
    r = requests.get(url)

    if r.status_code != 200:
        raise Exception(
            f"Did not connect successfully. HTTP status code: {r.status_code}\nURL: {url}"
        )

    soup = BeautifulSoup(r.text, "lxml")

    with open(file_to_write, "w") as file:
        file.write(soup.prettify())

    return None


def get_oral_arg_metadata(year):
    """
     Opens file for given year from 001_html, parses for date of oral argument,
     name of case, and URL of PDF.
     :param year: Used to tell function which year to process.
     :return: None
     """

    file_to_write = f"{path_to_root}/data/002_transcript_metadata/002_tr_meta_{year}.csv"

    # Check if file exists, if so, skip the whole function.
    if check_file(file_to_write):
        return None

    # Open the file for the year and save as soup.
    with open(f"{path_to_root}/data/001_html/001_html_{year}.txt", "r") as file:
        soup = BeautifulSoup(file, "lxml")

    # List will be used to write out a csv at end of function
    metadata = [f"'arg_id', 'name', 'pdf_url'"]

    # This td has all the data we need for each case
    for row in soup.findAll("td", attrs={"style": "text-align: left;"}):

        # The first span contains the link information and something I'm calling "argument_id"
        link = row.find("span", attrs={"style": "display:block;width:80px;float:left;"})
        a = link.find('a', href=True)
        arg_id = a.text.strip()
        pdf_link = a['href'].strip('..')

        # The second span as the name of the case
        name = row.find("span", attrs={"style" : "display:block;"}).text.strip()

        # Append to list as promised
        metadata.append(f"{arg_id}, {name}, {pdf_link}")

    # Save list to csv
    with open(f"{file_to_write}", "w") as file:
        file.write("\n".join(metadata))

    return None



year = 2016
get_transcript_html(year)
get_oral_arg_metadata(year)
